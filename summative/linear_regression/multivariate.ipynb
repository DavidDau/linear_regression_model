{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36e7e84",
   "metadata": {},
   "source": [
    "# Cardiovascular Disease Prediction using Linear Regression\n",
    "\n",
    "## Mission Statement\n",
    "To mitigate labor shortages and boost productivity by leveraging predictive analytics to identify and prevent cardio-related diseases early, ensuring a healthier workforce and a more resilient economy.\n",
    "\n",
    "## Dataset Features:\n",
    "- age: Age in years\n",
    "- gender: Gender (1 = female, 2 = male)\n",
    "- height: Height in cm\n",
    "- weight: Weight in kg\n",
    "- ap_hi: Systolic blood pressure\n",
    "- ap_lo: Diastolic blood pressure\n",
    "- cholesterol: Cholesterol level (1 = normal, 2 = above normal, 3 = well above normal)\n",
    "- gluc: Glucose level (1 = normal, 2 = above normal, 3 = well above normal)\n",
    "- smoke: Smoking (0 = no, 1 = yes)\n",
    "- alco: Alcohol intake (0 = no, 1 = yes)\n",
    "- active: Physical activity (0 = no, 1 = yes)\n",
    "- cardio: Cardiovascular disease (0 = no, 1 = yes) - TARGET VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e2a18",
   "metadata": {},
   "source": [
    "## A. Data Visualization and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('cardio_base.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b36cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6724399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribution of target variable\n",
    "axes[0, 0].pie(df['cardio'].value_counts(), labels=['No Disease', 'Disease'], autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Distribution of Cardiovascular Disease')\n",
    "\n",
    "# Age distribution by cardio disease\n",
    "sns.boxplot(data=df, x='cardio', y='age', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Age Distribution by Cardiovascular Disease')\n",
    "axes[0, 1].set_xlabel('Cardio Disease (0=No, 1=Yes)')\n",
    "\n",
    "# Blood pressure relationship\n",
    "sns.scatterplot(data=df, x='ap_hi', y='ap_lo', hue='cardio', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Blood Pressure Relationship')\n",
    "axes[1, 0].set_xlabel('Systolic BP')\n",
    "axes[1, 0].set_ylabel('Diastolic BP')\n",
    "\n",
    "# BMI calculation and distribution\n",
    "df['bmi'] = df['weight'] / (df['height'] / 100) ** 2\n",
    "sns.boxplot(data=df, x='cardio', y='bmi', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('BMI Distribution by Cardiovascular Disease')\n",
    "axes[1, 1].set_xlabel('Cardio Disease (0=No, 1=Yes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix of All Features')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance based on correlation with target\n",
    "target_corr = abs(correlation_matrix['cardio']).sort_values(ascending=False)\n",
    "print(\"\\nFeature Correlation with Target (Cardiovascular Disease):\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"Original features:\", df.columns.tolist())\n",
    "\n",
    "# Create additional features\n",
    "df['pulse_pressure'] = df['ap_hi'] - df['ap_lo']  # Pulse pressure\n",
    "df['age_risk'] = (df['age'] > 50).astype(int)  # Age risk factor\n",
    "df['bp_risk'] = ((df['ap_hi'] > 140) | (df['ap_lo'] > 90)).astype(int)  # High BP risk\n",
    "df['lifestyle_risk'] = df['smoke'] + df['alco'] - df['active']  # Lifestyle risk score\n",
    "\n",
    "print(\"\\nNew features added:\")\n",
    "print(\"- BMI: Body Mass Index\")\n",
    "print(\"- Pulse Pressure: Systolic - Diastolic BP\")\n",
    "print(\"- Age Risk: Age > 50 (binary)\")\n",
    "print(\"- BP Risk: High blood pressure indicator\")\n",
    "print(\"- Lifestyle Risk: Smoking + Alcohol - Activity\")\n",
    "\n",
    "print(\"\\nFinal dataset shape:\", df.shape)\n",
    "print(\"Features:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9279ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features to drop based on low correlation and redundancy\n",
    "features_to_drop = ['height', 'weight']  # We have BMI now\n",
    "print(f\"Dropping features: {features_to_drop}\")\n",
    "print(\"Reason: Redundant features (height, weight replaced by BMI)\")\n",
    "\n",
    "# Create final feature set\n",
    "X = df.drop(['cardio'] + features_to_drop, axis=1)\n",
    "y = df['cardio']\n",
    "\n",
    "print(\"\\nFinal feature set:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c189975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversion and standardization\n",
    "print(\"Data types before conversion:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Ensure all features are numeric\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features: {numeric_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "# Convert any non-numeric to numeric if needed\n",
    "for col in categorical_features:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nData standardized successfully!\")\n",
    "print(f\"Mean of scaled training data: {np.mean(X_train_scaled):.6f}\")\n",
    "print(f\"Std of scaled training data: {np.std(X_train_scaled):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05539406",
   "metadata": {},
   "source": [
    "## B. Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Linear Regression with Gradient Descent\n",
    "class LinearRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.costs_train = []\n",
    "        self.costs_test = []\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_test=None, y_test=None):\n",
    "        # Initialize parameters\n",
    "        n_samples, n_features = X_train.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Forward pass - training\n",
    "            y_pred_train = np.dot(X_train, self.weights) + self.bias\n",
    "            \n",
    "            # Calculate cost - training\n",
    "            cost_train = (1 / (2 * n_samples)) * np.sum((y_pred_train - y_train) ** 2)\n",
    "            self.costs_train.append(cost_train)\n",
    "            \n",
    "            # Calculate cost - test (if provided)\n",
    "            if X_test is not None and y_test is not None:\n",
    "                y_pred_test = np.dot(X_test, self.weights) + self.bias\n",
    "                cost_test = (1 / (2 * len(y_test))) * np.sum((y_pred_test - y_test) ** 2)\n",
    "                self.costs_test.append(cost_test)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            dw = (1 / n_samples) * np.dot(X_train.T, (y_pred_train - y_train))\n",
    "            db = (1 / n_samples) * np.sum(y_pred_train - y_train)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Train custom linear regression\n",
    "lr_custom = LinearRegressionGD(learning_rate=0.01, n_iterations=1000)\n",
    "lr_custom.fit(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"Custom Linear Regression trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cedda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(lr_custom.costs_train, label='Training Loss', color='blue')\n",
    "plt.plot(lr_custom.costs_test, label='Test Loss', color='red')\n",
    "plt.title('Training and Test Loss Curves')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Log scale for better visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lr_custom.costs_train, label='Training Loss', color='blue')\n",
    "plt.plot(lr_custom.costs_test, label='Test Loss', color='red')\n",
    "plt.title('Training and Test Loss Curves (Log Scale)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train scikit-learn Linear Regression for comparison\n",
    "lr_sklearn = LinearRegression()\n",
    "lr_sklearn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_custom = lr_custom.predict(X_train_scaled)\n",
    "y_pred_test_custom = lr_custom.predict(X_test_scaled)\n",
    "y_pred_train_sklearn = lr_sklearn.predict(X_train_scaled)\n",
    "y_pred_test_sklearn = lr_sklearn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Custom Linear Regression (Gradient Descent):\")\n",
    "print(f\"Training MSE: {mean_squared_error(y_train, y_pred_train_custom):.6f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, y_pred_test_custom):.6f}\")\n",
    "print(f\"Training R¬≤: {r2_score(y_train, y_pred_train_custom):.6f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_test_custom):.6f}\")\n",
    "\n",
    "print(\"\\nScikit-learn Linear Regression:\")\n",
    "print(f\"Training MSE: {mean_squared_error(y_train, y_pred_train_sklearn):.6f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, y_pred_test_sklearn):.6f}\")\n",
    "print(f\"Training R¬≤: {r2_score(y_train, y_pred_train_sklearn):.6f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_test_sklearn):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61360b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots before and after regression\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Before regression - raw data\n",
    "axes[0, 0].scatter(range(len(y_train)), y_train, alpha=0.6, color='blue', label='Actual')\n",
    "axes[0, 0].set_title('Training Data - Before Regression')\n",
    "axes[0, 0].set_xlabel('Sample Index')\n",
    "axes[0, 0].set_ylabel('Cardiovascular Disease')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# After regression - training predictions\n",
    "axes[0, 1].scatter(range(len(y_train)), y_train, alpha=0.6, color='blue', label='Actual')\n",
    "axes[0, 1].plot(range(len(y_train)), y_pred_train_sklearn, color='red', linewidth=2, label='Predicted')\n",
    "axes[0, 1].set_title('Training Data - After Linear Regression')\n",
    "axes[0, 1].set_xlabel('Sample Index')\n",
    "axes[0, 1].set_ylabel('Cardiovascular Disease')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Test data - before\n",
    "axes[1, 0].scatter(range(len(y_test)), y_test, alpha=0.6, color='green', label='Actual')\n",
    "axes[1, 0].set_title('Test Data - Before Regression')\n",
    "axes[1, 0].set_xlabel('Sample Index')\n",
    "axes[1, 0].set_ylabel('Cardiovascular Disease')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Test data - after regression\n",
    "axes[1, 1].scatter(range(len(y_test)), y_test, alpha=0.6, color='green', label='Actual')\n",
    "axes[1, 1].plot(range(len(y_test)), y_pred_test_sklearn, color='red', linewidth=2, label='Predicted')\n",
    "axes[1, 1].set_title('Test Data - After Linear Regression')\n",
    "axes[1, 1].set_xlabel('Sample Index')\n",
    "axes[1, 1].set_ylabel('Cardiovascular Disease')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted scatter plots\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Training data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, y_pred_train_sklearn, alpha=0.6)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Training Data: Actual vs Predicted')\n",
    "plt.grid(True)\n",
    "\n",
    "# Test data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_test_sklearn, alpha=0.6, color='green')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Test Data: Actual vs Predicted')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489bd2b",
   "metadata": {},
   "source": [
    "## C. Model Comparison: Linear Regression vs Decision Trees vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Store predictions\n",
    "    predictions[name] = {\n",
    "        'train': y_pred_train,\n",
    "        'test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    results[name] = {\n",
    "        'Train MSE': train_mse,\n",
    "        'Test MSE': test_mse,\n",
    "        'Train R¬≤': train_r2,\n",
    "        'Test R¬≤': test_r2,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'CV R¬≤ Mean': cv_scores.mean(),\n",
    "        'CV R¬≤ Std': cv_scores.std()\n",
    "    }\n",
    "\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94649751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in a comprehensive table\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"MODEL COMPARISON RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.round(6))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df['Test R¬≤'].idxmax()\n",
    "print(f\"\\nüèÜ BEST PERFORMING MODEL: {best_model_name}\")\n",
    "print(f\"Test R¬≤ Score: {results_df.loc[best_model_name, 'Test R¬≤']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# R¬≤ scores comparison\n",
    "model_names = list(results.keys())\n",
    "train_r2_scores = [results[name]['Train R¬≤'] for name in model_names]\n",
    "test_r2_scores = [results[name]['Test R¬≤'] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, train_r2_scores, width, label='Train R¬≤', alpha=0.8)\n",
    "axes[0, 0].bar(x + width/2, test_r2_scores, width, label='Test R¬≤', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Models')\n",
    "axes[0, 0].set_ylabel('R¬≤ Score')\n",
    "axes[0, 0].set_title('Model Performance Comparison (R¬≤ Score)')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(model_names, rotation=45)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# MSE comparison\n",
    "train_mse_scores = [results[name]['Train MSE'] for name in model_names]\n",
    "test_mse_scores = [results[name]['Test MSE'] for name in model_names]\n",
    "\n",
    "axes[0, 1].bar(x - width/2, train_mse_scores, width, label='Train MSE', alpha=0.8)\n",
    "axes[0, 1].bar(x + width/2, test_mse_scores, width, label='Test MSE', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Models')\n",
    "axes[0, 1].set_ylabel('Mean Squared Error')\n",
    "axes[0, 1].set_title('Model Performance Comparison (MSE)')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(model_names, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_means = [results[name]['CV R¬≤ Mean'] for name in model_names]\n",
    "cv_stds = [results[name]['CV R¬≤ Std'] for name in model_names]\n",
    "\n",
    "axes[1, 0].bar(model_names, cv_means, yerr=cv_stds, capsize=5, alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Models')\n",
    "axes[1, 0].set_ylabel('Cross-Validation R¬≤ Score')\n",
    "axes[1, 0].set_title('Cross-Validation Performance')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "if 'Random Forest' in models:\n",
    "    rf_model = models['Random Forest']\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    axes[1, 1].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    axes[1, 1].set_xlabel('Feature Importance')\n",
    "    axes[1, 1].set_title('Random Forest Feature Importance')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac14f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    y_pred = predictions[name]['test']\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    axes[i].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[i].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[i].set_xlabel('Predicted Values')\n",
    "    axes[i].set_ylabel('Residuals')\n",
    "    axes[i].set_title(f'{name} - Residual Plot')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Save model and scaler\n",
    "with open('best_cardio_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(X.columns.tolist(), f)\n",
    "\n",
    "print(f\"‚úÖ Best model ({best_model_name}) saved as 'best_cardio_model.pkl'\")\n",
    "print(\"‚úÖ Scaler saved as 'scaler.pkl'\")\n",
    "print(\"‚úÖ Feature names saved as 'feature_names.pkl'\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CARDIOVASCULAR DISEASE PREDICTION MODEL - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üéØ Mission: Predict cardiovascular disease to ensure healthier workforce\")\n",
    "print(f\"üìä Dataset: {df.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üìà Test R¬≤ Score: {results[best_model_name]['Test R¬≤']:.4f}\")\n",
    "print(f\"üìâ Test MSE: {results[best_model_name]['Test MSE']:.6f}\")\n",
    "print(f\"üéØ Cross-Validation R¬≤: {results[best_model_name]['CV R¬≤ Mean']:.4f} ¬± {results[best_model_name]['CV R¬≤ Std']:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
